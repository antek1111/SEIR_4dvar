{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis and Data Assimilation on the example of Lorenz and SEIR models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today's tutorial will be divided into three parts:\n",
    "\n",
    "1. Introduction to Lorenz and SEIR models\n",
    "1. Sensitivity analysis\n",
    "1. Data assimilation with 4DVar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xd5sJkFzB3J8"
   },
   "source": [
    "# Introduction to Lorenz and SEIR models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjQTLTtPB_sz"
   },
   "source": [
    "### Lorenz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjzDm4II4am1"
   },
   "source": [
    "![Lorenz equations](images/lorenz.png)\n",
    "\n",
    "source: https://en.wikipedia.org/wiki/Lorenz_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w8VBKtli4am2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgXBCQ6qCpdO"
   },
   "source": [
    "Method that computes one timestep of Lorenz model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmTJ5WBpCisT"
   },
   "outputs": [],
   "source": [
    "def lorenz_step(state, _, rho, sigma, beta):\n",
    "    x, y, z = state  # Unpack the state vector\n",
    "    return sigma * (y - x), x * (rho - z) - y, x * y - beta * z  # Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7ZkYK8EC_em"
   },
   "source": [
    "Let's draw the model's trajectory for the basic parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "v5ci8COp4am5",
    "outputId": "c65b645e-0030-4560-baa1-1b830bce17a8"
   },
   "outputs": [],
   "source": [
    "rho = 28.0\n",
    "sigma = 10.0\n",
    "beta = 8.0 / 3.0\n",
    "\n",
    "state0 = [1,1,1]\n",
    "\n",
    "t = np.arange(0.0, 40.0, 0.01)\n",
    "\n",
    "states = odeint(lorenz_step, state0, t, args=(rho,sigma,beta))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection=\"3d\")\n",
    "ax.plot(states[:, 0], states[:, 1], states[:, 2])\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELMzNWomCGRD"
   },
   "source": [
    "### SEIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2--G1cpw4anA"
   },
   "source": [
    "![SEIR epidemic model](images/seir.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "at-kcNQey4ji"
   },
   "source": [
    "SEIR is a model that simulates an outbreak of a virus.\n",
    "\n",
    "The population is divided into four groups:\n",
    "* S - group of humans **susceptible** to be exposed to the virus. Before an epidemic starts, all population members belong to this group.\n",
    "* E - group of people that were **exposed** to the virus. In this stage they already started to develop the illness, but they don't show symptoms nor infect others yet.\n",
    "* I - group of **infectious** individuals, who can pass the virus to susceptible members.\n",
    "* R - people that have already **recovered** from the infection.\n",
    "\n",
    "Additionaly we can specify two more groups:\n",
    "* D - a group of individuals that are **dead** as a result of the infection\n",
    "* N - total number of alive individuals\n",
    "\n",
    "---\n",
    "\n",
    "There are four parameters. The reasonable bounds for them are given in the brackets:\n",
    "* alfa - the case fatality rate - fraction of Infected group that dies each day. [0.001, 0.01]\n",
    "* beta - probability of disease transmission times the number of contacts per day. [0, 7]\n",
    "* epsilon - rate of progression from Exposed to Infectious (so 1/eps is the incubation period). [0.05, 0.5] (from 2 to 20 days)\n",
    "* gamma - rate of progression from Infectious to Recovered (so 1/gamma is the length of the infectious period) [0.05, 0.5] (from 2 to 20 days)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "These are the equations which represent the group size in the following time step:\n",
    "\n",
    "S = S - S \\* beta \\* I / N  \n",
    "E = E + S \\* beta \\* I / N - eps \\* E  \n",
    "I = I + eps \\* E - (alfa + gamma) \\* I  \n",
    "R = R + gamma \\* I  \n",
    "D = alfa \\* I  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuK3_lsz4anB"
   },
   "outputs": [],
   "source": [
    "def seir_step(state):\n",
    "    state = list(np.ravel(state))\n",
    "    state = list(map(lambda x : max(x, 0), state))\n",
    "    S_old, E_old, I_old, R_old, D_old, alfa, beta, eps, gamma = state\n",
    "\n",
    "    N = S_old + E_old + I_old + R_old\n",
    "    D = D_old + alfa * I_old\n",
    "    S = S_old - S_old * beta * I_old / N\n",
    "    E = E_old + S_old * beta * I_old / N - eps * E_old\n",
    "    I = I_old + eps * E_old - (alfa + gamma) * I_old\n",
    "    R = R_old + gamma * I_old\n",
    "\n",
    "    results = [S, E, I, R, D, alfa, beta, eps, gamma]\n",
    "    return np.array(results).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "407TX6iHEHrR"
   },
   "source": [
    "Let's simulate a sample epidemic\n",
    "\n",
    "**TASK 1** Choose some values from the reasonable bounds introduced earlier and observe the effect on the plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "o-d_FqZlJbcq",
    "outputId": "4a31b0b2-4bcf-4f1b-98bd-7e7bbca90b95"
   },
   "outputs": [],
   "source": [
    "# TODO: insert values for alfa, beta, eps, gamma\n",
    "params = [ ??? ]\n",
    "seird = [40000000, 1, 0, 0, 0]\n",
    "state = np.array(seird + params).reshape(-1, 1)\n",
    "\n",
    "days = 365\n",
    "\n",
    "states = np.empty((days,5))\n",
    "for i in range(days):\n",
    "    states[i]  = state[:5][:,0]\n",
    "    state = seir_step(state)\n",
    "\n",
    "plt.plot( range(days),states[:,0])\n",
    "plt.plot( range(days),states[:,1])\n",
    "plt.plot( range(days),states[:,2])\n",
    "plt.plot( range(days),states[:,3])\n",
    "plt.plot( range(days),states[:,4])\n",
    "print('Susceptible, exposed, infectious, recovered and dead individuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "OkrfMn3blj6w",
    "outputId": "0bf0e482-beb9-4bdd-806d-cbdad44d3108"
   },
   "outputs": [],
   "source": [
    "plt.plot( range(days),states[:,1])\n",
    "plt.plot( range(days),states[:,2])\n",
    "plt.plot( range(days),states[:,4])\n",
    "print('Exposed, infectious and dead individuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUoMCLorWSsx"
   },
   "source": [
    "# Sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YP3woLqJvF8f"
   },
   "source": [
    "In order to check which parameters of the model have the biggest influence on the output, we can perform a Sensitivity Analysis. SALib is a Python library that implements it. It does two things:\n",
    "\n",
    "\n",
    "1.   Generates a set of inputs to be fed to the model\n",
    "2.   Analyses outputs returned by the model for this set of inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcJrzxW5WZVT"
   },
   "outputs": [],
   "source": [
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jHDeQzuwwLe"
   },
   "source": [
    "### Sensitivity analysis - Lorenz 63 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hK_Sg-qHw1zr"
   },
   "source": [
    "We will perform SA on Lorenz 63 model. First, we need to define the parameters of the model and generate a set of input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gP7l3vuH0oSS",
    "outputId": "22009d75-8418-4f66-f3bf-3038d4816596"
   },
   "outputs": [],
   "source": [
    "problem = {\n",
    "    'num_vars': 3,\n",
    "    'names': ['rho', 'sigma', 'beta'],\n",
    "    'bounds': [[14.0,42.0],\n",
    "               [3.0, 20.0],\n",
    "               [7.0/3.0, 9.0/3.0]]\n",
    "}\n",
    "\n",
    "#Let's generate 20 values for each parameter:\n",
    "input = saltelli.sample(problem, 20)\n",
    "\n",
    "print(input.shape)\n",
    "print(input[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeCRqCCI0uaq"
   },
   "source": [
    "Now, we need to define our model and generate an output value for each input (each set of parameters)\n",
    "\n",
    "Lorenz model has a 3-dimensional state (x,y,z) for each timestep. However, SA can only analyse a single output for a given input.\n",
    "\n",
    "In order to deal with that, we will analyse the sensitivity in the 3 dimensions separately. We will analyse the standard deviation of values in each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E4IOwAGB1C8S"
   },
   "outputs": [],
   "source": [
    "def generate_outputs_lorenz(parameter_combinations):\n",
    "    # We need an output array with a row for each generated input and 3 colums for 3 output variables (x, y, z)\n",
    "    output = np.empty( shape=(parameter_combinations.shape[0],3) )\n",
    "    # Define timesteps for Lorenz 63 integration\n",
    "    t = np.arange(0.0, 40.0, 0.01)\n",
    "\n",
    "    for i, params in enumerate(parameter_combinations):\n",
    "        initial_state = [1,1,1]\n",
    "        rho, sigma, beta = params[0], params[1], params[2]\n",
    "\n",
    "        # Get states in each timestep:\n",
    "        states = odeint(lorenz_step, initial_state, t, args=(rho, sigma, beta))\n",
    "\n",
    "        # We take the standard deviation in each dimension as the output.\n",
    "        output[i] = np.std(states, axis=0)\n",
    "    return output\n",
    "\n",
    "output = generate_outputs_lorenz(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDPWnOco1DIK"
   },
   "source": [
    "Finally, we can analyse the sensitivity. We analyse it in respect to each output dimension separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8keVdDIaWmx0",
    "outputId": "18f6f99b-abe3-4c3c-c779-206a7c5f34ae"
   },
   "outputs": [],
   "source": [
    "Si_X = sobol.analyze(problem, output[:,0], print_to_console=False)['S1']\n",
    "Si_Y = sobol.analyze(problem, output[:,1], print_to_console=False)['S1']\n",
    "Si_Z = sobol.analyze(problem, output[:,2], print_to_console=False)['S1']\n",
    "\n",
    "print('           ', list(map(lambda name: name + ' '*(5-len(name)),    problem['names'])))\n",
    "print('X analysis:', list(map(lambda number: '{0:.3f}'.format(number),  Si_X)))\n",
    "print('Y analysis:', list(map(lambda number: '{0:.3f}'.format(number),  Si_Y)))\n",
    "print('Z analysis:', list(map(lambda number: '{0:.3f}'.format(number),  Si_Z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3tY07Oi8Bvm"
   },
   "source": [
    "The higher the value, the more the parameter affects the behaviour of the model.\n",
    "The rho parameter influences all dimensions of model significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCtKhCBRBCqM"
   },
   "source": [
    "### Sensitivity analysis - SEIR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRw_NbOXBHvP"
   },
   "source": [
    "Now we will perform a similar SA on the SEIR model\n",
    "\n",
    "**TASK 2** Just like in the Lorenz example, define the number of variables, their names and the bounds. Use the bounds provided in the definition of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nzotHuEnqvE",
    "outputId": "a851ea8c-8702-4abe-d86c-1795ec5b180d"
   },
   "outputs": [],
   "source": [
    "problem_seir = {\n",
    "    'num_vars': ??? ,\n",
    "    'names': ??? ,\n",
    "    'bounds': ???\n",
    "}\n",
    "\n",
    "input = saltelli.sample(problem_seir, 100)\n",
    "\n",
    "print(input.shape)\n",
    "print(input[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we encounter the same problem: SA can analyse only one 1-dimensional output for a given input, while SEIR is a time series with 5 groups (5 dimensions). We will deal with that in two ways separately:\n",
    "* analyse the final amount of dead individuals\n",
    "* analyse the maximum amount of infected individuals at a single moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KCiq1VAsmLAO"
   },
   "outputs": [],
   "source": [
    "def generate_outputs_seir(parameter_combinations):\n",
    "    # We need an output array with a row for each generated input\n",
    "    output_final = np.empty( shape=(parameter_combinations.shape[0]) )\n",
    "    output_max = np.empty( shape=(parameter_combinations.shape[0]) )\n",
    "\n",
    "    for i, params in enumerate(parameter_combinations):\n",
    "        initial_state = np.array([39900000, 60000, 10000, 80000, 2300])\n",
    "        state = np.concatenate((initial_state, params))\n",
    "\n",
    "        max_infected = 0\n",
    "        for step in range(200):\n",
    "            state = seir_step(state)\n",
    "            if state[:][2] > max_infected:\n",
    "                max_infected = state[:][2]\n",
    "        output_final[i] = state[:][4]\n",
    "        output_max[i] = max_infected\n",
    "    return output_final, output_max\n",
    "\n",
    "output_final, output_max = generate_outputs_seir(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DKS1TvlNmLIk",
    "outputId": "a64f11d5-0a63-4879-9d22-0914c22acee8"
   },
   "outputs": [],
   "source": [
    "print('                      ', list(map(lambda name: name + ' '*(5-len(name)),    problem_seir['names'])))\n",
    "Si = sobol.analyze(problem_seir, output_final, print_to_console=False)['S1']\n",
    "print('Final deaths analysis:', list(map(lambda number: '{0:.3f}'.format(number),  Si)))\n",
    "Si = sobol.analyze(problem_seir, output_max, print_to_console=False)['S1']\n",
    "print('Max infected analysis:', list(map(lambda number: '{0:.3f}'.format(number),  Si)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMC3dOoX4amg"
   },
   "source": [
    "# Data assimilation with 4DVar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm realizes an estimation of the state of a dynamic system, by a variational minimization method of the classical J function in data assimilation:\n",
    "![4dvar function](images/4dvar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JmObKff4am9"
   },
   "source": [
    "For calculations we used ADAO python library - [documentation](https://docs.salome-platform.org/latest/gui/ADAO/en/ref_algorithm_4DVAR.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUlknPyM4am0"
   },
   "source": [
    "### 4d var with Lorenz 63 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will try to find parameters of Lorenz63 model using 4d-var data assimilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78tzYjbw4am_"
   },
   "outputs": [],
   "source": [
    "from data_assimilation import assimilate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-bhH23p4anA"
   },
   "outputs": [],
   "source": [
    "rho = 28.0\n",
    "sigma = 10.0\n",
    "beta = 8.0 / 3.0\n",
    "\n",
    "d = 0.01\n",
    "xb = [1., 1., 1.] + [rho, sigma, beta]\n",
    "xb = np.array(xb).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 4D-Var assimilation we need to provide 2 funtions:\n",
    " * observation operator - function that returns observation based on given state\n",
    " * evolution step - function that transforms state from one time point to the next one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 3** write observation operator for Lorenz63 model (Hint: state is an array \\[x, y, z, rho, sigma, beta\\])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz_obs_operator(state):\n",
    "    return ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz_evol_step(state):\n",
    "    list(np.ravel(state))\n",
    "    x, y, z, rho, sigma, beta = state  # Unpack the state vector\n",
    "    rho, sigma, beta = list(map(lambda x : abs(x), [rho, sigma, beta]))\n",
    "    dx, dy, dz = lorenz_step([x, y, z], \"\", rho, sigma, beta)\n",
    "    return np.array([x + d * dx, y + d * dy, z + d * dz, rho, sigma, beta]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 4** using above functions write a function that generates test observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to generate observations based on evolution function and observation operator\n",
    "def prepare_obs(state, obs_operator, evolution_function, size=100):\n",
    "    observations = []\n",
    "    for i in range(size):\n",
    "        observations.append(???)\n",
    "        state = ???\n",
    "    return observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we generate truth observations, because assimilation process is quite slow, generate only 200 observations\n",
    "yobs = np.array(prepare_obs(xb, lorenz_obs_operator, lorenz_evol_step, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection=\"3d\")\n",
    "ax.plot(yobs[:, 0].flatten(), yobs[:, 1].flatten(), yobs[:, 2].flatten())\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we provide parameters, that assimilation will start from\n",
    "xb = [1., 1., 1.] + [20., 10., 5.]\n",
    "xb = np.array(xb).reshape(-1, 1)\n",
    "error_vector = [0.1, 0.1, 0.1, 100, 100, 100] # diagonal of covariance matrix of each parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we run 4D-Var data assimilation on generated observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = assimilate(xb, yobs, lorenz_obs_operator, lorenz_evol_step, error_vector=error_vector, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate observations from assimilated parameters\n",
    "res = np.array(prepare_obs(np.array(result).reshape(-1, 1), lorenz_obs_operator, lorenz_evol_step, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection=\"3d\")\n",
    "ax.plot(res[:, 0].flatten(), res[:, 1].flatten(), res[:, 2].flatten())\n",
    "ax.plot(yobs[:, 0].flatten(), yobs[:, 1].flatten(), yobs[:, 2].flatten())\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmD6dS_m4anA"
   },
   "source": [
    "### SEIR epidemic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to generate data based on SEIR model and then based on these observations we will use 4D-Var data assimilation to fit parameters.\n",
    "\n",
    "In our case observations is total number of deaths to given day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5** write observation operator for Lorenz63 model (Hint: state is an array \\[s, e, i, r, d, alpha, beta, eps, gamma\\])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kNoUMY784anD"
   },
   "outputs": [],
   "source": [
    "def seir_obs_operator(state):\n",
    "    D = ??\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVzfv6yg4anE"
   },
   "outputs": [],
   "source": [
    "# TODO define some random parameters to generate observations\n",
    "params = [???, ???, ???, ???]\n",
    "seird = ???, ???, ???, ???, ???]\n",
    "state = np.array(seird + params).reshape(-1, 1)\n",
    "days = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pY-pJ4Ke4anF"
   },
   "outputs": [],
   "source": [
    "# generate observations based on prepared earlier parameters\n",
    "yobs = prepare_obs(state, seir_obs_operator, seir_step, size=days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9balXy-4anF",
    "outputId": "f17b6ad1-665c-4c6f-dd7f-c198790a27f2"
   },
   "outputs": [],
   "source": [
    "# now we try to find parameters that will result in matching observations\n",
    "result = assimilate(seird + [0.01, 0.5, 0.5, 0.5], yobs, seir_obs_operator, seir_step, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate new observations based on result from data assimilation\n",
    "res = prepare_obs(result, seir_obs_operator, seir_step, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(days), yobs)\n",
    "plt.plot(range(days), res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwLYz0dy4anG"
   },
   "source": [
    "### Assimilation of actual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to fir parameters to the actual data concerning COVID-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v1qAwxnf4anG"
   },
   "outputs": [],
   "source": [
    "# data can be found in file `covid-deaths.csv` \n",
    "from data_assimilation import load_data\n",
    "yobs = load_data(size = 100, country = 'POL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJHRK60x4anG",
    "outputId": "042cf68a-932a-42b2-b9e4-425ec00bdc9f"
   },
   "outputs": [],
   "source": [
    "seird = [36000000, 30000, 10000, 80000, 2349]\n",
    "result = assimilate(seird + [0.01, 0.1, 0.1, 0.1], yobs, seir_obs_operator, seir_step, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQmDUPI_4anH"
   },
   "outputs": [],
   "source": [
    "res = prepare_obs(result, seir_obs_operator, seir_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(100), yobs)\n",
    "plt.plot(range(100), res)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4dvar_seir_new.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "p3",
   "language": "python",
   "name": "p3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
